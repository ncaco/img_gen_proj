{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "setup",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©: qwen3:4b\n",
            "   Ollama ì„œë²„: http://localhost:11434\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
        "load_dotenv()\n",
        "\n",
        "# ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ: 'local' ë˜ëŠ” 'openai'\n",
        "USE_LOCAL_MODEL = True  # Falseë¡œ ë³€ê²½í•˜ë©´ OpenAI ì‚¬ìš©\n",
        "\n",
        "if USE_LOCAL_MODEL:\n",
        "    try:\n",
        "        import requests\n",
        "        # Ollama ì‚¬ìš© (ë¡œì»¬ ëª¨ë¸)\n",
        "        OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
        "        OLLAMA_MODEL = \"qwen3:4b\"  # ë˜ëŠ” \"qwen2.5\", \"gemma2\" ë“±\n",
        "        print(f\"âœ… ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©: {OLLAMA_MODEL}\")\n",
        "        print(f\"   Ollama ì„œë²„: {OLLAMA_BASE_URL}\")\n",
        "    except ImportError:\n",
        "        print(\"âš ï¸ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install requests\")\n",
        "else:\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    print(\"âœ… OpenAI API ì‚¬ìš©: gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "card-info",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‹ ì…ë ¥ëœ ì¹´ë“œ ì •ë³´:\n",
            "  type: ê°œë°œì\n",
            "  attribute: ì–´ë‘ \n",
            "  rarity: â­\n",
            "  attack: 1000\n",
            "  health: 1000\n",
            "  skill1_name: ë””ë²„ê¹…\n",
            "  skill1_description: 'ëª°ì…' ëª¨ë“œë¡œ íƒœì„¸ë¥¼ ë°”ê¿‰ë‹ˆë‹¤.\n",
            "  skill2_name: ì»´íŒŒì¼\n",
            "  skill2_description: ëª¨ë“  ê°œë°œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
            "  flavor_text: ì„¸ìƒ ëª¨ë“  0 ê³¼ 1 ì€ ë‚˜ì˜ ì†ì—...\n"
          ]
        }
      ],
      "source": [
        "# ì¹´ë“œ ì •ë³´ ì…ë ¥ (ì˜ˆì‹œ)\n",
        "card_info = {\n",
        "    \"type\": \"ê°œë°œì\",\n",
        "    \"attribute\": \"ì–´ë‘ \",\n",
        "    \"rarity\": \"â­\",\n",
        "    \"attack\": \"1000\",\n",
        "    \"health\": \"1000\",\n",
        "    \"skill1_name\": \"ë””ë²„ê¹…\",\n",
        "    \"skill1_description\": \"'ëª°ì…' ëª¨ë“œë¡œ íƒœì„¸ë¥¼ ë°”ê¿‰ë‹ˆë‹¤.\",\n",
        "    \"skill2_name\": \"ì»´íŒŒì¼\",\n",
        "    \"skill2_description\": \"ëª¨ë“  ê°œë°œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\",\n",
        "    \"flavor_text\": \"ì„¸ìƒ ëª¨ë“  0 ê³¼ 1 ì€ ë‚˜ì˜ ì†ì—...\"\n",
        "}\n",
        "\n",
        "print(\"ğŸ“‹ ì…ë ¥ëœ ì¹´ë“œ ì •ë³´:\")\n",
        "for key, value in card_info.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "generate-names",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¤– ì¹´ë“œ ì´ë¦„ ì¶”ì²œ ì¤‘... (ë¡œì»¬ ëª¨ë¸: Ollama)\n",
            "\n",
            "âœ… ì¶”ì²œëœ ì¹´ë“œ ì´ë¦„:\n",
            "==================================================\n",
            "ì–´ë‘  ë¹„íŠ¸\n",
            "ë””ë²„ê·¸ ì–´ë‘ \n",
            "0ê³¼ 1ì˜ ì†\n",
            "==================================================\n",
            "\n",
            "ğŸ“ ì¶”ì²œëœ ì´ë¦„ ê°œìˆ˜: 3ê°œ\n"
          ]
        }
      ],
      "source": [
        "# ì¹´ë“œ ì´ë¦„ ì¶”ì²œ í•¨ìˆ˜\n",
        "\n",
        "def generate_card_names_local(card_info, model=OLLAMA_MODEL):\n",
        "    \"\"\"ë¡œì»¬ ëª¨ë¸(Ollama)ì„ ì‚¬ìš©í•˜ì—¬ ì¹´ë“œ ì´ë¦„ ìƒì„±\"\"\"\n",
        "    prompt = f\"\"\"ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë ˆì´ë”© ì¹´ë“œ ê²Œì„ì— ì í•©í•œ ì¹´ë“œ ì´ë¦„ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ì¹´ë“œ ì •ë³´:\n",
        "- íƒ€ì…: {card_info['type']}\n",
        "- ì†ì„±: {card_info['attribute']}\n",
        "- ë“±ê¸‰: {card_info['rarity']}\n",
        "- ê³µê²©ë ¥: {card_info['attack']}\n",
        "- ì²´ë ¥: {card_info['health']}\n",
        "- ìŠ¤í‚¬1: {card_info['skill1_name']} - {card_info['skill1_description']}\n",
        "- ìŠ¤í‚¬2: {card_info['skill2_name']} - {card_info['skill2_description']}\n",
        "- í”Œë ˆì´ë²„ í…ìŠ¤íŠ¸: {card_info['flavor_text']}\n",
        "\n",
        "ìš”êµ¬ì‚¬í•­:\n",
        "1. ì¹´ë“œì˜ íƒ€ì…, ì†ì„±, ìŠ¤í‚¬ì„ ë°˜ì˜í•œ ì´ë¦„\n",
        "2. íŠ¸ë ˆì´ë”© ì¹´ë“œ ê²Œì„ì— ì í•©í•œ ë©‹ì§„ ì´ë¦„\n",
        "3. í•œêµ­ì–´ë¡œ ì‘ì„±\n",
        "4. 2-4ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ê°„ê²°í•œ ì´ë¦„\n",
        "5. ì¹´ë“œì˜ íŠ¹ì„±ê³¼ ë¶„ìœ„ê¸°ë¥¼ ì˜ í‘œí˜„í•˜ëŠ” ì´ë¦„\n",
        "\n",
        "ì¹´ë“œ ì´ë¦„ 3ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. ê° ì´ë¦„ì€ í•œ ì¤„ì— í•˜ë‚˜ì”©, ë²ˆí˜¸ ì—†ì´ ì œì‹œí•´ì£¼ì„¸ìš”.\"\"\"\n",
        "    \n",
        "    response = requests.post(\n",
        "        f\"{OLLAMA_BASE_URL}/api/generate\",\n",
        "        json={\n",
        "            \"model\": model,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"response\"].strip()\n",
        "    else:\n",
        "        raise Exception(f\"Ollama API ì˜¤ë¥˜: {response.status_code} - {response.text}\")\n",
        "\n",
        "\n",
        "def generate_card_names_openai(card_info):\n",
        "    \"\"\"OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹´ë“œ ì´ë¦„ ìƒì„±\"\"\"\n",
        "    prompt = f\"\"\"ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë ˆì´ë”© ì¹´ë“œ ê²Œì„ì— ì í•©í•œ ì¹´ë“œ ì´ë¦„ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ì¹´ë“œ ì •ë³´:\n",
        "- íƒ€ì…: {card_info['type']}\n",
        "- ì†ì„±: {card_info['attribute']}\n",
        "- ë“±ê¸‰: {card_info['rarity']}\n",
        "- ê³µê²©ë ¥: {card_info['attack']}\n",
        "- ì²´ë ¥: {card_info['health']}\n",
        "- ìŠ¤í‚¬1: {card_info['skill1_name']} - {card_info['skill1_description']}\n",
        "- ìŠ¤í‚¬2: {card_info['skill2_name']} - {card_info['skill2_description']}\n",
        "- í”Œë ˆì´ë²„ í…ìŠ¤íŠ¸: {card_info['flavor_text']}\n",
        "\n",
        "ìš”êµ¬ì‚¬í•­:\n",
        "1. ì¹´ë“œì˜ íƒ€ì…, ì†ì„±, ìŠ¤í‚¬ì„ ë°˜ì˜í•œ ì´ë¦„\n",
        "2. íŠ¸ë ˆì´ë”© ì¹´ë“œ ê²Œì„ì— ì í•©í•œ ë©‹ì§„ ì´ë¦„\n",
        "3. í•œêµ­ì–´ë¡œ ì‘ì„±\n",
        "4. 2-4ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ê°„ê²°í•œ ì´ë¦„\n",
        "5. ì¹´ë“œì˜ íŠ¹ì„±ê³¼ ë¶„ìœ„ê¸°ë¥¼ ì˜ í‘œí˜„í•˜ëŠ” ì´ë¦„\n",
        "\n",
        "ì¹´ë“œ ì´ë¦„ 3ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. ê° ì´ë¦„ì€ í•œ ì¤„ì— í•˜ë‚˜ì”©, ë²ˆí˜¸ ì—†ì´ ì œì‹œí•´ì£¼ì„¸ìš”.\"\"\"\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"ë‹¹ì‹ ì€ íŠ¸ë ˆì´ë”© ì¹´ë“œ ê²Œì„ì˜ ì¹´ë“œ ì´ë¦„ì„ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.8,\n",
        "        max_tokens=200\n",
        "    )\n",
        "    \n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "# ì¹´ë“œ ì´ë¦„ ìƒì„± ì‹¤í–‰\n",
        "try:\n",
        "    if USE_LOCAL_MODEL:\n",
        "        print(\"\\nğŸ¤– ì¹´ë“œ ì´ë¦„ ì¶”ì²œ ì¤‘... (ë¡œì»¬ ëª¨ë¸: Ollama)\")\n",
        "        recommended_names = generate_card_names_local(card_info)\n",
        "    else:\n",
        "        print(\"\\nğŸ¤– ì¹´ë“œ ì´ë¦„ ì¶”ì²œ ì¤‘... (OpenAI: gpt-4o-mini)\")\n",
        "        recommended_names = generate_card_names_openai(card_info)\n",
        "    \n",
        "    print(\"\\nâœ… ì¶”ì²œëœ ì¹´ë“œ ì´ë¦„:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(recommended_names)\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # ì´ë¦„ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬\n",
        "    name_list = [name.strip() for name in recommended_names.split('\\n') if name.strip()]\n",
        "    print(f\"\\nğŸ“ ì¶”ì²œëœ ì´ë¦„ ê°œìˆ˜: {len(name_list)}ê°œ\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    if USE_LOCAL_MODEL:\n",
        "        print(\"\\nğŸ’¡ Ollama ì„¤ì¹˜ ë° ì‹¤í–‰ ë°©ë²•:\")\n",
        "        print(\"1. Ollama ì„¤ì¹˜: https://ollama.com/download\")\n",
        "        print(f\"2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull {OLLAMA_MODEL}\")\n",
        "        print(\"3. Ollama ì„œë²„ ì‹¤í–‰ í™•ì¸: ollama serve\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
